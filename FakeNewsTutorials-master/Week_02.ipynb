{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></div><div class=\"lev1 toc-item\"><a href=\"#Semantics\" data-toc-modified-id=\"Semantics-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Semantics</a></div><div class=\"lev2 toc-item\"><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Motivation</a></div><div class=\"lev2 toc-item\"><a href=\"#Term-Document\" data-toc-modified-id=\"Term-Document-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Term-Document</a></div><div class=\"lev3 toc-item\"><a href=\"#Bag-of-Words\" data-toc-modified-id=\"Bag-of-Words-221\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Bag-of-Words</a></div><div class=\"lev4 toc-item\"><a href=\"#Cleaning-Text-Data\" data-toc-modified-id=\"Cleaning-Text-Data-2211\"><span class=\"toc-item-num\">2.2.1.1&nbsp;&nbsp;</span>Cleaning Text Data</a></div><div class=\"lev4 toc-item\"><a href=\"#Stemming-and-Lemmatizing\" data-toc-modified-id=\"Stemming-and-Lemmatizing-2212\"><span class=\"toc-item-num\">2.2.1.2&nbsp;&nbsp;</span>Stemming and Lemmatizing</a></div><div class=\"lev3 toc-item\"><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-222\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>TF-IDF</a></div><div class=\"lev2 toc-item\"><a href=\"#Term-Context\" data-toc-modified-id=\"Term-Context-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Term-Context</a></div><div class=\"lev1 toc-item\"><a href=\"#Word2Vec\" data-toc-modified-id=\"Word2Vec-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Word2Vec</a></div><div class=\"lev2 toc-item\"><a href=\"#Continuous-Bag-of-Words\" data-toc-modified-id=\"Continuous-Bag-of-Words-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Continuous Bag of Words</a></div><div class=\"lev2 toc-item\"><a href=\"#Skip-gram\" data-toc-modified-id=\"Skip-gram-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Skip-gram</a></div><div class=\"lev2 toc-item\"><a href=\"#Example\" data-toc-modified-id=\"Example-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Example</a></div><div class=\"lev1 toc-item\"><a href=\"#Doc2Vec\" data-toc-modified-id=\"Doc2Vec-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Doc2Vec</a></div><div class=\"lev2 toc-item\"><a href=\"#Doc2Vec,-the-most-powerful-extension-of-word2vec\" data-toc-modified-id=\"Doc2Vec,-the-most-powerful-extension-of-word2vec-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Doc2Vec, the most powerful extension of word2vec</a></div><div class=\"lev2 toc-item\"><a href=\"#Distrubted-Memory-(DM)\" data-toc-modified-id=\"Distrubted-Memory-(DM)-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Distrubted Memory (DM)</a></div><div class=\"lev2 toc-item\"><a href=\"#Distrubted-Bag-of-Words-(DBOW)\" data-toc-modified-id=\"Distrubted-Bag-of-Words-(DBOW)-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Distrubted Bag of Words (DBOW)</a></div><div class=\"lev1 toc-item\"><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Exercises</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes you have done the setup required in Week 1.\n",
    "\n",
    "In this lecture we will be using Gensim and NLTK, two widely used Python Natural Language Processing libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -f -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pip_install(*packages):\n",
    "    '''\n",
    "    Author: Sy Hwang, Hollis Nolan, Shuheng Liu \n",
    "    \n",
    "    Install packages using pip\n",
    "    Alternatively just use command line\n",
    "    pip install package_name\n",
    "    '''\n",
    "    import pip\n",
    "    if int(pip.__version__.split(\".\")[0]) >= 10:  # since 10.0.0, pip does not support pip.main() any more\n",
    "        from pip._internal import main\n",
    "    else:\n",
    "        from pip import main\n",
    "\n",
    "    for package in packages:\n",
    "        try:\n",
    "            main([\"install\", \"--upgrade\", package, \"--user\"])\n",
    "        except Exception as e:\n",
    "            print(\"Unable to install {} using pip.\".format(package))\n",
    "            print(\"Exception:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached https://files.pythonhosted.org/packages/3a/bc/1415be59292a23ff123298b4b46ec4be80b3bfe72c8d188b58ab2653dee4/gensim-3.8.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Collecting smart_open>=1.7.0 (from gensim)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/37/c0/25d19badc495428dec6a4bf7782de617ee0246a9211af75b302a2681dea7/smart_open-1.8.4.tar.gz (63kB)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from smart_open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from smart_open>=1.7.0->gensim) (2.21.0)\n",
      "Collecting boto3 (from smart_open>=1.7.0->gensim)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/fb/e5/7ff9a5f23b3e94aefccc18f9d2493ddbeb31725986ab5ae4552387381e01/boto3-1.9.198-py2.py3-none-any.whl (128kB)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.7.0->gensim) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from requests->smart_open>=1.7.0->gensim) (1.24.1)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->smart_open>=1.7.0->gensim)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart_open>=1.7.0->gensim)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Collecting botocore<1.13.0,>=1.12.198 (from boto3->smart_open>=1.7.0->gensim)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Cache entry deserialization failed, entry ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading https://files.pythonhosted.org/packages/8b/2d/74e83c1cc3e8ab5c9675b2990af2f4c2a7b66379627deef4b08780fe6b23/botocore-1.12.198-py2.py3-none-any.whl (5.6MB)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.15,>=0.10 in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.198->boto3->smart_open>=1.7.0->gensim) (0.14)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in c:\\users\\pipi\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.198->boto3->smart_open>=1.7.0->gensim) (2.8.0)\n",
      "Building wheels for collected packages: gensim, smart-open\n",
      "  Building wheel for gensim (setup.py): started\n",
      "  Building wheel for gensim (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\pipi\\AppData\\Local\\pip\\Cache\\wheels\\2c\\19\\c6\\bf38e867cb6e75999e3ff80302eb27bdf488b333efadfbfed7\n",
      "  Building wheel for smart-open (setup.py): started\n",
      "  Building wheel for smart-open (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\pipi\\AppData\\Local\\pip\\Cache\\wheels\\5f\\ea\\fb\\5b1a947b369724063b2617011f1540c44eb00e28c3d2ca8692\n",
      "Successfully built gensim smart-open\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto3-1.9.198 botocore-1.12.198 gensim-3.8.0 jmespath-0.9.4 s3transfer-0.2.1 smart-open-1.8.4\n",
      "Collecting nltk\n",
      "  Downloading https://files.pythonhosted.org/packages/87/16/4d247e27c55a7b6412e7c4c86f2500ae61afcbf5932b9e3491f8462f8d9e/nltk-3.4.4.zip (1.5MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\pipi\\\\AppData\\\\Local\\\\Temp\\\\pip-req-tracker-_jz44m28\\\\b3095b1324fb85a822887988cbb36067fa60285c59804dcfe133f1c4'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip_install('gensim', 'nltk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\pipi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\gutenberg.zip.\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\pipi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pipi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pipi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('reuters')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ROOTDIR = os.path.abspath(os.path.dirname('__file__'))\n",
    "DATADIR = os.path.join(ROOTDIR, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to be able to categorize text, we need to be able to generate features for articles, paragraphs, sentences and other bodies of text, based on the information they contain and what they represent. There are a number of ways to achieve this and we will go over 3 approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-Document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words\n",
    "\n",
    "One of the simplest ways to extract features from text is to just count how many times a word appears in a body of text. In this model, the order of words does not matter and only the number of occurrences of each unique term for each document is taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load movie reviews dataset\n",
    "df = pd.read_csv(os.path.join(DATADIR, 'movie_reviews.csv'), nrows=100000)\n",
    "texts = df.text.values #pd.Series -> np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Transform each review string as a list of token strings. May take a few seconds\n",
    "tokenized = [nltk.word_tokenize(review) for review in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example review:\n",
      "   Raw: So ingenious in concept, design and execution that you could watch it on a postage stamp-sized screen and still be engulfed by its charm. \n",
      "\n",
      "   Tokenized: ['So', 'ingenious', 'in', 'concept', ',', 'design', 'and', 'execution', 'that', 'you', 'could', 'watch', 'it', 'on', 'a', 'postage', 'stamp-sized', 'screen', 'and', 'still', 'be', 'engulfed', 'by', 'its', 'charm', '.']\n"
     ]
    }
   ],
   "source": [
    "n = 10 #arbitrary pick\n",
    "print('Example review:\\n   Raw: {} \\n\\n   Tokenized: {}'.format(texts[n], [i for i in tokenized[n]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Cleaning Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing Stopwords and Punctuations, Lower-case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sometimes it's useful to drop __Stopwords__ when breaking down documents into units of tokens. Stopwords are terms that appear so frequently in a corpus that they provide little to no informative value to the task at hand. Common stopwords include words like *the*, *of*, *to*, and *for*.   \n",
    "- __Punctuations__ are very much the same; while they may provide linguistic context, punctuations can sometimes be too common to provide any value.\n",
    "\n",
    "Let's take a look at the most common tokens in our movie reviews dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.    .  freq:  102815\n",
      " 2.    ,  freq:   97049\n",
      " 3.  the  freq:   94390\n",
      " 4.    a  freq:   66933\n",
      " 5.   of  freq:   58012\n",
      " 6.  and  freq:   57274\n",
      " 7.   to  freq:   36228\n",
      " 8.   's  freq:   34515\n",
      " 9.   is  freq:   33891\n",
      "10.   it  freq:   30890\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Note that we convert all tokens to lower case, otherwise words like *The* and *the* are different tokens.\n",
    "token_counter = Counter(token.lower() for sentence in tokenized for token in sentence)\n",
    "top10 = token_counter.most_common()[:10]\n",
    "for i, t in enumerate(top10):\n",
    "    print('{:>2}.{:>5}  freq: {:>7}'.format(i+1, t[0], t[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are all either stopwords or punctuations!  \n",
    "Thankfully there's an easy way to remove them: `nltk` and the built-in `string` module have separate lists of stopwords and punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemming and Lemmatizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can also find lots of words that have similar meanings, but differ only by their conjugation and inflections. Sometimes it makes sense to normalize different forms of the same word to a single root token before indexing. There are two ways to do this:\n",
    "    - __Stemming__: heuristic approach that chops off the endings of different forms of words, trying to return the root morpheme that stays the same even with varying inflections.\n",
    "        - Example:\n",
    "            - I saw that movie and it was terrible $\\rightarrow$ I saw that movi and it wa terribl\n",
    "            - informative informational inform informing $\\rightarrow$ inform inform inform inform     \n",
    "\n",
    "    - __Lemmatizing__: returns the derivational normal form or the dictionary form of the word, called the lemma\n",
    "        - Example:\n",
    "            - I saw that movie and it was terrible $\\rightarrow$ I see that movie and it be terrible\n",
    "            - am are is be $\\rightarrow$ be be be be\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/preprocessing_text.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from itertools import chain\n",
    "\n",
    "def clean_text(tokenized_list, sw, punct, lemmatize=False):\n",
    "    new_list = []\n",
    "    for doc in tokenized_list:\n",
    "        new_list.append([token.lower() for token in doc if token.lower() not in chain(punct, sw)])\n",
    "    return new_list\n",
    "\n",
    "# Remove punctuations and stopwords, and lower-case text\n",
    "sw = stopwords.words('english')\n",
    "punct = punctuation\n",
    "cleaned = clean_text(tokenized, sw, punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pattern' package not found; tag filters are not available for English\n",
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "adding document #10000 to Dictionary(19384 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pipi\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding document #20000 to Dictionary(28227 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "adding document #30000 to Dictionary(34412 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "adding document #40000 to Dictionary(39845 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "adding document #50000 to Dictionary(45053 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "adding document #60000 to Dictionary(50133 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "adding document #70000 to Dictionary(54465 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "adding document #80000 to Dictionary(58483 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "adding document #90000 to Dictionary(62720 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...)\n",
      "built Dictionary(67641 unique tokens: ['...', 'entire', 'ever', 'filmgoers', 'generation']...) from 100000 documents (total 1149442 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "# Create a dictionary from list of documents in order to create BOW model\n",
    "dictionary = corpora.Dictionary(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example review featurized in Bag of Words :\n",
      " [('still', 1), ('charm', 1), ('concept', 1), ('could', 1), ('design', 1), ('engulfed', 1), ('execution', 1), ('ingenious', 1), ('postage', 1), ('screen', 1), ('stamp-sized', 1), ('watch', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Create a Corpus based on BOW Format.\n",
    "corpus = [dictionary.doc2bow(text) for text in cleaned]\n",
    "print('Example review featurized in Bag of Words :\\n {}'.format([(dictionary[i[0]], i[1]) for i in corpus[n]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when we use this model to featurize text:\n",
    "- The length of each feature vector will be the size of the vocabulary in the corpus\n",
    "- Thus each body of text will have a lot of zeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Term Frequency__: Number of occurrences of a word in a document  \n",
    "__Inverse Document Frequency__: Number of documents that contain a certain word scaled by a weight  \n",
    "__Term Frequency - Inverse Document Frequency__: (Number of ocurrences of word $w$ in text $T$) * $log$(Number of documents in a corpus/Number of documents containing word $w$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the TF-IDF scores of the previous movie review we examined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting document frequencies\n",
      "PROGRESS: processing document #0\n",
      "PROGRESS: processing document #10000\n",
      "PROGRESS: processing document #20000\n",
      "PROGRESS: processing document #30000\n",
      "PROGRESS: processing document #40000\n",
      "PROGRESS: processing document #50000\n",
      "PROGRESS: processing document #60000\n",
      "PROGRESS: processing document #70000\n",
      "PROGRESS: processing document #80000\n",
      "PROGRESS: processing document #90000\n",
      "calculating IDF weights for 100000 documents and 67640 features (1110955 matrix non-zeros)\n",
      "Example review featurized with TF-IDF scores : \n",
      "[('still', 0.152), ('charm', 0.206), ('concept', 0.244), ('could', 0.159), ('design', 0.25), ('engulfed', 0.431), ('execution', 0.259), ('ingenious', 0.293), ('postage', 0.414), ('screen', 0.176), ('stamp-sized', 0.458), ('watch', 0.191)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "#Create a TFIDF Model for the corpus\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "print('Example review featurized with TF-IDF scores : \\n{}'.format([(dictionary[i[0]], round(i[1],3)) for i in tfidf[corpus[n]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks much more like a feature vector that we can use for text categorization!  \n",
    "Note that in the TF-IDF model:\n",
    "- If a term frequently occurs in the corpus(i.e. stopwords, the term $like$), it is scaled to a lower score\n",
    "- Rarer terms will generally have higher scores. They tend to be more \"informative\" and descriptive.\n",
    "- A term that occurs frequently in a small number of documents within the corpus will have the highest scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/tfidf.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term-Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of NLP works regards as atomic symbols: king, queen, book, etc.\n",
    "\n",
    "In vector space terms, this vector has one $1 $ and a lot of zeros.   \n",
    "$king =  [1, 0, 0, 0, 0, 0, 0, 0, 0]$   \n",
    "$queen = [0, 1, 0, 0, 0, 0, 0, 0, 0]$   \n",
    "$book =  [0, 0, 1, 0, 0, 0, 0, 0, 0]$  \n",
    "\n",
    "It is called a \"one-hot\" encoding representation. It is a common way to represent categories in models. However, it is very sparse(as we saw from the BOW model); each row is mostly 0s.  \n",
    "You can get more value by representing a word by its neighorbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using entire documents, we can use small contexts to a term.\n",
    "- Paragraphs\n",
    "- Sentences\n",
    "- A window of a sequence of consecutive terms\n",
    "\n",
    "In this way, a word is defined over counts of context words. The assumption is that two words that appear in similar contexts are similar themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But count-based models have disadvantages:\n",
    "- vector sizes become huge, equal to vocabulary size\n",
    "    - sparsity\n",
    "    - curse of dimensionality (Go through [this notebook](https://github.com/mike-tamir/tamir_extras/blob/master/Curse_of_Dim_walkthrough.ipynb) for more detailed information)\n",
    "    - computationally expensive\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is an unsupervised neural network model that maximizes similarity between contextual neighbors while minimizing similarity for unseen contexts.\n",
    "Initial vectors are generated randomly and converge as the models is trained on the corpus through a sliding window.\n",
    "Target Vector sizes are set at the beginning of the training process, so the vectors are dense and do not need dimensionality reduction techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/cbow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training objective is to maiximize the probability of observing the correct target word $w_t$ given context words $w_{c1}, w_{c2}, ... w_{cj}$\n",
    "\n",
    " $$ C = -log p(w_t | w_{c1} ... w_{cj}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction vector is set as an average of all the context word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/skip-gram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training objective is to maiximize the probability of observing the correct context words $w_{ci}$ given target word $w_{t}$\n",
    "\n",
    " $$ C = -\\sum^{j}_{i=1}log p(w_{ci} | w_{t}) $$\n",
    " \n",
    "In this case, the prediction vector is the the target word vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try training our own word embeddings and looking at what we can do with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec\n",
    "- `size`: Number of dimensions for the word embedding model\n",
    "- `window`: Number of context words to observe in each direction\n",
    "- `min_count`: Minimum frequency for words included in model\n",
    "- `sg` (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram\n",
    "- `alpha`: Learning rate (initial); prevents model from over-correcting, enables finer tuning\n",
    "- `iterations`: Number of passes through dataset\n",
    "- `batch_words`: Number of words to sample from data during each pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting all words and their counts\n",
      "PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "PROGRESS: at sentence #10000, processed 256693 words, keeping 9207 word types\n",
      "PROGRESS: at sentence #20000, processed 567137 words, keeping 13603 word types\n",
      "PROGRESS: at sentence #30000, processed 918759 words, keeping 17616 word types\n",
      "PROGRESS: at sentence #40000, processed 1236460 words, keeping 19579 word types\n",
      "PROGRESS: at sentence #50000, processed 1508401 words, keeping 22623 word types\n",
      "PROGRESS: at sentence #60000, processed 1715918 words, keeping 27910 word types\n",
      "PROGRESS: at sentence #70000, processed 1915119 words, keeping 30708 word types\n",
      "PROGRESS: at sentence #80000, processed 2144824 words, keeping 35822 word types\n",
      "PROGRESS: at sentence #90000, processed 2415166 words, keeping 44470 word types\n",
      "collected 51134 word types from a corpus of 2621785 raw words and 98552 sentences\n",
      "Loading a fresh vocabulary\n",
      "min_count=5 retains 17011 unique words (33% of original 51134, drops 34123)\n",
      "min_count=5 leaves 2565427 word corpus (97% of original 2621785, drops 56358)\n",
      "deleting the raw counts dictionary of 51134 items\n",
      "sample=0.001 downsamples 53 most-common words\n",
      "downsampling leaves estimated 1802467 word corpus (70.3% of prior 2565427)\n",
      "estimated required memory for 17011 words and 300 dimensions: 49331900 bytes\n",
      "resetting layer weights\n",
      "training model with 3 workers on 17011 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "EPOCH 1 - PROGRESS: at 18.71% examples, 352174 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 36.99% examples, 377015 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 57.72% examples, 373241 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 1 - PROGRESS: at 79.81% examples, 359604 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 1 : training on 2621785 raw words (1802145 effective words) took 5.0s, 358228 effective words/s\n",
      "EPOCH 2 - PROGRESS: at 18.99% examples, 356586 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 37.25% examples, 380506 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 58.25% examples, 375658 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 2 - PROGRESS: at 80.17% examples, 361748 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 2 : training on 2621785 raw words (1803092 effective words) took 5.0s, 360238 effective words/s\n",
      "EPOCH 3 - PROGRESS: at 18.44% examples, 347404 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 36.68% examples, 375710 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 57.24% examples, 373603 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 79.27% examples, 358702 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 3 - PROGRESS: at 99.76% examples, 356945 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 3 : training on 2621785 raw words (1802590 effective words) took 5.0s, 356974 effective words/s\n",
      "EPOCH 4 - PROGRESS: at 18.71% examples, 352436 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 36.99% examples, 377199 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 57.72% examples, 374113 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 4 - PROGRESS: at 79.81% examples, 360168 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "EPOCH 4 - PROGRESS: at 100.00% examples, 357901 words/s, in_qsize 0, out_qsize 1\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 4 : training on 2621785 raw words (1802847 effective words) took 5.0s, 357832 effective words/s\n",
      "EPOCH 5 - PROGRESS: at 18.71% examples, 352528 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 5 - PROGRESS: at 36.99% examples, 375915 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 5 - PROGRESS: at 57.72% examples, 372906 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 5 - PROGRESS: at 79.81% examples, 359423 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "EPOCH 5 - PROGRESS: at 100.00% examples, 356883 words/s, in_qsize 0, out_qsize 1\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 5 : training on 2621785 raw words (1801977 effective words) took 5.1s, 356818 effective words/s\n",
      "EPOCH 6 - PROGRESS: at 18.44% examples, 347698 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 6 - PROGRESS: at 36.44% examples, 371842 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 6 - PROGRESS: at 56.72% examples, 369327 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 6 - PROGRESS: at 78.48% examples, 355311 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 6 - PROGRESS: at 99.20% examples, 353697 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 6 : training on 2621785 raw words (1802990 effective words) took 5.1s, 353266 effective words/s\n",
      "EPOCH 7 - PROGRESS: at 18.71% examples, 351841 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 36.99% examples, 377578 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 57.72% examples, 374637 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 7 - PROGRESS: at 79.81% examples, 360336 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 7 : training on 2621785 raw words (1802749 effective words) took 5.0s, 358087 effective words/s\n",
      "EPOCH 8 - PROGRESS: at 18.71% examples, 351310 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 36.99% examples, 377152 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 57.72% examples, 374649 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 8 - PROGRESS: at 79.81% examples, 361179 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 8 : training on 2621785 raw words (1802045 effective words) took 5.0s, 359833 effective words/s\n",
      "EPOCH 9 - PROGRESS: at 18.44% examples, 348097 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 36.68% examples, 374185 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 57.24% examples, 371398 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 79.27% examples, 357969 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 9 - PROGRESS: at 99.76% examples, 356178 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 9 : training on 2621785 raw words (1803085 effective words) took 5.1s, 356148 effective words/s\n",
      "EPOCH 10 - PROGRESS: at 18.71% examples, 350020 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 10 - PROGRESS: at 36.99% examples, 377587 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 10 - PROGRESS: at 57.72% examples, 375332 words/s, in_qsize 0, out_qsize 0\n",
      "EPOCH 10 - PROGRESS: at 79.81% examples, 361640 words/s, in_qsize 0, out_qsize 0\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 10 : training on 2621785 raw words (1803526 effective words) took 5.0s, 359946 effective words/s\n",
      "training on a 26217850 raw words (18027046 effective words) took 50.4s, 357591 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from gensim import models\n",
    "\n",
    "# Training word2vec model on Gutenberg corpus. This may take a few minutes.\n",
    "model = models.Word2Vec(gutenberg.sents(),\n",
    "                        size = 300,\n",
    "                        window = 5,\n",
    "                        min_count = 5,\n",
    "                        sg = 0,\n",
    "                        alpha = 0.025,\n",
    "                        iter = 10,\n",
    "                        batch_words = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://multithreaded.stitchfix.com/assets/images/blog/vectors.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word vectors are directions in space and can encode relationships between words.  \n",
    "\n",
    "The proximity of words to each other can be calculated through their cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('maid', 0.7113270163536072),\n",
       " ('child', 0.6988879442214966),\n",
       " ('lad', 0.6885336637496948),\n",
       " ('Farmer', 0.6741182208061218),\n",
       " ('girl', 0.6726040840148926),\n",
       " ('fellow', 0.613610565662384),\n",
       " ('mother', 0.6096839904785156),\n",
       " ('gentleman', 0.605623722076416),\n",
       " ('lady', 0.6028754711151123),\n",
       " ('Susan', 0.5991085171699524)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words closest to the token 'boy'\n",
    "model.wv.most_similar(positive=['boy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wine', 0.6826830506324768),\n",
       " ('bread', 0.6824086904525757),\n",
       " ('meat', 0.6805968284606934),\n",
       " ('cattle', 0.6408922076225281),\n",
       " ('flocks', 0.6404011249542236),\n",
       " ('corn', 0.6312136650085449),\n",
       " ('fruits', 0.628380537033081),\n",
       " ('wheat', 0.6257160902023315),\n",
       " ('prey', 0.6190413236618042),\n",
       " ('lambs', 0.6120137572288513)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words closest to the token 'food'\n",
    "model.wv.most_similar(positive=['food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('particularly', 0.5025079250335693),\n",
       " ('Fairfax', 0.4188178777694702),\n",
       " ('Anne', 0.40248051285743713),\n",
       " ('allowed', 0.3808298408985138),\n",
       " ('idle', 0.3794349431991577),\n",
       " ('Mary', 0.3785339593887329),\n",
       " ('relating', 0.3769521117210388),\n",
       " ('absolutely', 0.3764355480670929),\n",
       " ('longing', 0.3748558461666107),\n",
       " ('elegant', 0.37446707487106323)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# she + her + hers + herself - he - him - his - himself\n",
    "model.wv.most_similar(positive=['she','her','hers','herself'], negative=['he','him','his','himself'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's limit ourselves to top 50 words that related to food to visualize how they relate in vector space\n",
    "f_tokens = [token for token,weight in model.wv.most_similar(positive=['food'], topn=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise\n",
    "vectors = [model.wv[word] for word in f_tokens]\n",
    "dist_matrix = pairwise.pairwise_distances(vectors, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "mds = MDS(n_components = 2, dissimilarity='precomputed')\n",
    "embeddings = mds.fit_transform(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "_, ax = plt.subplots(figsize=(14,10))\n",
    "ax.scatter(embeddings[:,0], embeddings[:,1], alpha=0)\n",
    "for i in range(len(vectors)):\n",
    "    ax.annotate(f_tokens[i], ((embeddings[i,0], embeddings[i,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What kind of clusters of food-themed terms can you notice?**\n",
    "\n",
    "- Words that are grouped together generally appear in the same context\n",
    "    - Some examples:\n",
    "        - vineyards - vines - grapes\n",
    "        - hunger - thirst\n",
    "        - corn - wheat - barley\n",
    "- Note that we're dealing with vectors that have been reduced from 300 dimensions to 2 dimensions for visualization purposes. We have also limited our subset to those nearest to the token *food*.\n",
    "- Also note that we are working with the [Gutenberg corpus](http://www.nltk.org/book/ch02.html), which is a collection of mostly old English literature books, such as works from Jane Austen and William Shakespeare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "Doc2Vec, the most powerful extension of word2vec\n",
    "---\n",
    "\n",
    "Doc2vec (aka paragraph2vec or sentence embeddings) extrapolates the word2vec algorithm to larger blocks of text, such as sentences, paragraphs or entire documents. \n",
    "\n",
    "![](images/overview_word.png)\n",
    "\n",
    "![](images/overview_paragraph.png)\n",
    "\n",
    "Every paragraph is mapped to a unique vector, represented by a column in matrix D and every word is also mapped to a unique vector, represented by a column in matrix W . \n",
    "The paragraph vector and word vectors are averaged or concatenated to predict the next word in a context. \n",
    "\n",
    "Each additional context does not have be a fixed length (because it is vectorized and projected into the same space).\n",
    "\n",
    "Additional parameters but the updates are sparse thus still efficent.\n",
    "\n",
    "__2 architectures__:\n",
    "\n",
    "1. Distrubted Memory (DM)\n",
    "2. Distrubted Bag of Words (DBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distrubted Memory (DM)\n",
    "\n",
    "__Highlights__:\n",
    "\n",
    "- Assign and randomly initialize paragraph vector for each doc\n",
    "- Predict next word using context words and paragraph vector\n",
    "- Slide context window across doc but keep paragraph vector fixed (hence: Distrubted Memory)\n",
    "- Update weights via SGD and backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distrubted Bag of Words (DBOW)\n",
    "\n",
    "__Highlights__:\n",
    "\n",
    "- ONLY use paragraph vectors (no word vectors)\n",
    "- Take a window of words in a paragraph and randomly sample which ones to predict using paragraph vector\n",
    "- Simpler, more memory effecient\n",
    "\n",
    "![](images/DBOW.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try building our own Doc2Vec model with Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec Parameters\n",
    "- `size`: Number of dimensions for the embedding model\n",
    "- `window`: Number of context words to observe in each direction within a document\n",
    "- `min_count`: Minimum frequency for words included in model\n",
    "- `dm` (distributed memory): '0' indicates DBOW model; '1' indicates DM\n",
    "- `alpha`: Learning rate (initial); prevents model from over-correcting, enables finer tuning\n",
    "- `iter`: Number of iterations through corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting all words and their counts\n",
      "PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "PROGRESS: at example #10000, processed 1432016 words (7925120/s), 60879 word types, 10000 tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pipi\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:362: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "C:\\Users\\pipi\\Anaconda3\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected 63346 word types and 10788 unique tags from a corpus of 10788 examples and 1548597 words\n",
      "Loading a fresh vocabulary\n",
      "min_count=5 retains 15255 unique words (24% of original 63346, drops 48091)\n",
      "min_count=5 leaves 1472902 word corpus (95% of original 1548597, drops 75695)\n",
      "deleting the raw counts dictionary of 63346 items\n",
      "sample=0.001 downsamples 45 most-common words\n",
      "downsampling leaves estimated 1118205 word corpus (75.9% of prior 1472902)\n",
      "estimated required memory for 15255 words and 300 dimensions: 57185100 bytes\n",
      "resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Tokenize Reuters corpus\n",
    "tokenized_docs = [nltk.word_tokenize(reuters.raw(fileid)) for fileid in reuters.fileids()]\n",
    "\n",
    "# Convert tokenized documents to TaggedDocuments\n",
    "tagged_docs = [TaggedDocument(doc, tags=[idx]) for idx, doc in enumerate(tokenized_docs)]\n",
    "\n",
    "# Create and train the doc2vec model. May take a few seconds\n",
    "doc2vec = Doc2Vec(size=300, window=5, min_count=5, dm = 1, iter=10)\n",
    "\n",
    "# Build the word2vec model from the corpus\n",
    "doc2vec.build_vocab(tagged_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"tag 'doc003' not seen in training corpus/invalid\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-d81db404919a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdoc2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Does anyone remember when Madonna was considered shocking?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'doc003'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m   1197\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_docs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_int_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoctags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rawint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1199\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tag '%s' not seen in training corpus/invalid\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"tag 'doc003' not seen in training corpus/invalid\""
     ]
    }
   ],
   "source": [
    "doc2vec.infer_vector(\"Does anyone remember when Madonna was considered shocking?\")\n",
    "doc2vec.docvecs['doc003']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also fortify your Doc2Vec models with pre-trained Word2Vec models.\n",
    "Let's try re-training with GoogleNews-trained word vectors.  \n",
    "Download [here](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)  \n",
    "(Size is 1.5gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Doc2Vec' object has no attribute 'intersect_word2vec_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-bfe9681b854b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#This may take a few minutes to run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mw2v_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Users\\pipi\\Desktop\\FakeNewsTutorials-master\\JupyterNotebook\\Hw 2\"\u001b[0m\u001b[1;31m# your saved location of GoogleNews-vectors-negative300.bin.gz\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdoc2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersect_word2vec_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2v_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Doc2Vec' object has no attribute 'intersect_word2vec_format'"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.corpus import reuters\n",
    "#This may take a few minutes to run\n",
    "w2v_loc = \"Users\\pipi\\Desktop\\FakeNewsTutorials-master\\JupyterNotebook\\Hw 2\"# your saved location of GoogleNews-vectors-negative300.bin.gz\n",
    "doc2vec.intersect_word2vec_format(w2v_loc, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec.train(tagged_docs, epochs=10, total_examples=doc2vec.corpus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what you have learned from Week 1 and today's lecture, build a binary classifier for the movie reviews dataset in `data/movie_reviews.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding document #0 to Dictionary(0 unique tokens: [])\n",
      "built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "consider setting layer size to a multiple of 4 for greater performance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting all words and their counts\n",
      "PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "collected 12 word types and 9 unique tags from a corpus of 9 examples and 29 words\n",
      "Loading a fresh vocabulary\n",
      "min_count=1 retains 12 unique words (100% of original 12, drops 0)\n",
      "min_count=1 leaves 29 word corpus (100% of original 29, drops 0)\n",
      "deleting the raw counts dictionary of 12 items\n",
      "sample=0.001 downsamples 12 most-common words\n",
      "downsampling leaves estimated 3 word corpus (12.1% of prior 29)\n",
      "estimated required memory for 12 words and 5 dimensions: 6660 bytes\n",
      "resetting layer weights\n",
      "training model with 4 workers on 12 vocabulary and 5 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "worker thread finished; awaiting finish of 3 more threads\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 1 : training on 29 raw words (13 effective words) took 0.0s, 7281 effective words/s\n",
      "worker thread finished; awaiting finish of 3 more threads\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 2 : training on 29 raw words (12 effective words) took 0.0s, 6145 effective words/s\n",
      "worker thread finished; awaiting finish of 3 more threads\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 3 : training on 29 raw words (11 effective words) took 0.0s, 4602 effective words/s\n",
      "worker thread finished; awaiting finish of 3 more threads\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 4 : training on 29 raw words (9 effective words) took 0.0s, 5530 effective words/s\n",
      "worker thread finished; awaiting finish of 3 more threads\n",
      "worker thread finished; awaiting finish of 2 more threads\n",
      "worker thread finished; awaiting finish of 1 more threads\n",
      "worker thread finished; awaiting finish of 0 more threads\n",
      "EPOCH - 5 : training on 29 raw words (15 effective words) took 0.0s, 8673 effective words/s\n",
      "training on a 145 raw words (60 effective words) took 0.0s, 2673 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving Doc2Vec object under C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz, separately None\n",
      "saved C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz\n",
      "loading Doc2Vec object from C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz\n",
      "loading vocabulary recursively from C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz.vocabulary.* with mmap=None\n",
      "loading trainables recursively from C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz.trainables.* with mmap=None\n",
      "loading wv recursively from C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz.wv.* with mmap=None\n",
      "loading docvecs recursively from C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz.docvecs.* with mmap=None\n",
      "loaded C:\\Users\\pipi\\AppData\\Local\\Temp\\GoogleNews-vectors-negative300.bin.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pipi\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "newmodel = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
    "fname = get_tmpfile(\"GoogleNews-vectors-negative300.bin.gz\")\n",
    "\n",
    "newmodel.save(fname)\n",
    "newmodel = Doc2Vec.load(fname)  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "248px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
